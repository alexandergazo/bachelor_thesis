\chapter{Dynamical Systems}
\label{chap:intr}

\section{Systems of First Order Differential Equations}

\begin{remark}
	Let $f(t)$ be a function of time $t\in\R^+$. We denote its derivative with respect to $t$ by $$\dot{f}(t)=\frac{d}{dt}f(t)\ .$$
\end{remark}

\begin{definition}
	A \termdef{system of linear differential equations of order  one with constant coefficients} is the system 
	\begin{align*}
		\dot{x}_1(t)&=a_{1,1}x_1(t)+\ldots+a_{1,n}x_n(t) \\
		&\vdotswithin{=} \\
		\dot{x}_n(t)&=a_{n,1}x_1(t)+\ldots+a_{n,n}x_n(t)\ .
	\end{align*}
	This system can be written in the matrix form $$\dot{x}(t)=Ax(t)\ ,$$ where $x(t)=(x_1(t),\ldots,x_n(t))^T \in \R^n, x_i\colon\R^+\to\R,$ is a \termdef{state vector} (\termdef{state} for short) of the system and the matrix $A\in \R^{n\times n}$, $A=(a_{i,j})$ is a \termdef{matrix of coefficients} of the system. The \termdef{initial condition} of the system is the state $x(0)$.

	This system is also called a \termdef{linear autonomous system}.
\end{definition}

We use the matrix form, as it is a very compact way of describing such a system.

To express the solution of a linear autonomous system in a similarly compact way, we establish the notion of the matrix exponential.

\begin{definition}
	Let $X$ be a real square matrix. The exponential of $X$, denoted by $e^X$, is the square matrix of the same type defined by the series $$e^{X}=\sum _{k=0}^{\infty}\frac{1}{k!}X^{k}\ ,$$
	where $X^0$ is defined to be the identity matrix $I$ of the same type as $X$.
\end{definition}

For this definition to make sense, we need to show that the series converges for any real square matrix. Firstly, we define what it means for a matrix series to converge. In this text, we define the convergence using the Frobenius norm.

\begin{definition}
	\termdef{Frobenius norm} is a matrix norm, denoted as $\norm{\cdot}_F$, which for an arbitrary $n \times m$ matrix $A$ is defined as $$\norm{A}_F=\sqrt{\sum^n_{i=1}\sum^m_{j=1}\abs{a_{i,j}}^2}\ .$$
\end{definition}

\begin{lemma}
\label{lem:frobNormProperties}
	The Frobenius norm satisfies the following statements for any matrices $A$, $B$, $C\in \R^{n \times m}$, $D\in\R^{m\times r}$ and any scalar $\alpha \in \R$.
	\begin{enumerate}
		\item $\norm{A+B}_F\leq\norm{A}_F+\norm{B}_F\ ,$
		\item $\norm{\alpha A}_F=\abs{\alpha}\norm{A}_F\ ,$
		\item $\norm{A}_F\geq 0$ with equality occurring if and only if $A=O_{n \times m}\ ,$
		\item $\norm{CD}_F\leq\norm{C}_F\norm{D}_F\ .$
	\end{enumerate}
\end{lemma}

\begin{proof}
	The first three points can be simply shown using the definition of the Frobenius form and properties of the absolute value. 

	The fourth point follows from the Cauchy–Schwarz inequality 
	$$\norm{CD}^2_F=\sum^n_{i=1}\sum^r_{j=1}\abs{c_i\cdot d_j}^2 \leq \sum^n_{i=1}\sum^r_{j=1}\norm{c_i}_2^2\norm{d_j}_2^2=\sum^n_{i=1}\norm{c_i}_2^2\sum^r_{j=1}\norm{d_j}_2^2=\norm{C}^2_F\norm{D}^2_F\ ,$$
	where $\norm*{\cdot}_2$ denotes the Euclidean norm, $c_i$ denotes the $i$-th row vector of the matrix $C$ and $d_i$ denotes the $i$-th column vector of the matrix $D$.
\end{proof}

\begin{lemma}
\label{lem:elementAbsoluteSize}
	The absolute value of any element of a matrix is always less than or equal to the Frobenius norm of the matrix. In particular, for a matrix \linebreak $A^k=(a_{i,j}^{(k)})_{n\times n}$, where $A\in\R^{n\times n}$, it holds for every position $(i,j)$ that 
	$$\abs*{a_{i,j}^{(k)}}\leq\norm*{A^k}_F\leq\norm{A}^k_F.$$
\end{lemma}

\begin{proof}
	For an arbitrary element of the matrix $X=(x_{i,j})_{n\times m}$ it holds
	$$\abs*{x_{i,j}}\leq \sqrt{\sum^n_{i=1}\sum^m_{j=1}\abs*{x_{i,j}}^2}=\norm{X}_F\ .$$
	It follows 
	$$\abs*{a_{i,j}^{(k)}}\leq\norm*{A^k}_F\leq\norm{A}^k_F\ ,$$
	where the second inequality follows from the repeated use of the fourth point of Lemma \ref{lem:frobNormProperties}.
\end{proof}

\begin{cor}
	\label{cor:elementConvergence}
	Let us have a matrix $A^k=(a_{i,j}^{(k)})_{n\times n}$. Then the series $\sum^\infty_{k=0}\frac{b^k}{k!}a_{i,j}^{(k)}$ converges absolutely for any $b\in\R$.
\end{cor}

\begin{proof}
	By Lemma \ref{lem:elementAbsoluteSize}, for any $N\in\N$, we have
	$$\sum^N_{k=0}\abs{\frac{b^k}{k!}a_{i,j}^{(k)}}\leq\sum^N_{k=0}\frac{\abs{b}^k}{k!}\abs{a_{i,j}^{(k)}}\leq\sum^N_{k=0}\frac{\abs{b}^k}{k!}\norm{A}_F^{k}=\sum^N_{k=0}\frac{\norm{bA}_F^k}{k!}\ .$$
	Then 
	$$\sum^\infty_{k=0}\abs{\frac{b^k}{k!}a_{i,j}^{(k)}}=\lim_{N\to\infty}\sum^N_{k=0}\abs{\frac{b^k}{k!}a_{i,j}^{(k)}}\leq\lim_{N\to\infty}\sum^N_{k=0}\frac{\norm{bA}_F^k}{k!}=\sum^\infty_{k=0}\frac{\norm{bA}_F^k}{k!}=e^{\norm{bA}_F}\ .$$
\end{proof}

\begin{definition}
	A matrix sequence $\{A_k\}_{k=0}^\infty$ of $n \times m$ matrices is said to \termdef{converge} to a $n\times m$ matrix $A$, denoted $A_k\longrightarrow A$, if $$\forall\varepsilon\in\R, \varepsilon>0\quad\exists n_0\in\N\quad\forall n\in\N,n\geq n_0:||A_n-A||_F<\varepsilon\ .$$
\end{definition}

\begin{lemma}
\label{lem:elementwiseConvergence}
	A matrix sequence $\{A_k=(a^{(k)}_{i,j})_{n\times m}\}_{k=0}^\infty$ converges to a matrix \linebreak $A=(a_{i,j})_{n\times m}$ if and only if it converges elementwise, in other words $$\forall i\in\{1,\ldots,n\}\quad\forall j\in\{1,\ldots,m\} : a^{(k)}_{i,j}\xrightarrow{k\rightarrow\infty}a_{i,j}\ .$$
\end{lemma}

\begin{proof}
	Let $A_k \rightarrow A$. For any $\varepsilon\in\R^+$ we can find such $n_0$ that $\norm{A_n-A}_F<\varepsilon$ for every $n\geq n_0$. By Lemma \ref{lem:elementAbsoluteSize}, we then have $$\abs*{a^{(n)}_{i,j}-a_{i,j}}\leq \norm{A_n-A}_F<\varepsilon\ .$$ It follows that $\{A_k\}_{k=0}^\infty$ converges to $A$ elementwise.

	Conversely, let $\varepsilon$ be a positive real number. For every position $(i,j)$ we find such $k_{i,j}$ that $$\forall k\geq k_{i,j}:\abs*{a^{(k)}_{i,j}-a_{i,j}}<\frac{\varepsilon}{\sqrt{nm}}\ .$$ We put $N_0=\text{max}\{k_{i,j}\}$. Now $\forall k\in\N, k\geq N_0$ it holds $$||A_k-A||_F=\sqrt{\sum^n_{i=1}\sum^m_{j=1}|a^{(k)}_{i,j}-a_{i,j}|^2}<\sqrt{nm\frac{\varepsilon^2}{nm}}=\varepsilon\ .$$
\end{proof}

\begin{claim}
\label{claim:matrixExpConv}
	The matrix exponential is well defined, that is, the matrix series \label{lem:point:expConv} $\sum _{k=0}^{\infty}\frac{1}{k!}X^{k}$ converges for any matrix $X$.
\end{claim}

\begin{proof}
	\sloppy
	Let $X^k=(x_{i,j}^{(k)})_{n\times n}$. By Corollary \ref{cor:elementConvergence} every element of the matrix $\sum^\infty_{k=0}\frac{1}{k!}X^k=\left(\sum^\infty_{k=0}\frac{1}{k!}x^{(k)}_{i,j}\right)_{n\times n}$ converges absolutely. Therefore, the matrix series converges elementwise to some matrix $Y$ (we denote this matrix by $e^X$).
\end{proof}

\begin{lemma}
\label{lem:matrixSeriesFactoring}
	Let $\{A_k\}_{k=0}^\infty$ be a matrix sequence, where $A_k\in\R^{n\times m}$, and let $B\in\R^{r\times n}$, $C\in\R^{m\times s}$. If $\sum^\infty_{k=0}A_k$ converges, then also $\sum^\infty_{k=0}BA_kC$ converges, and the following equality holds:
	$$\sum^\infty_{k=0}BA_kC=B\left(\sum^\infty_{k=0}A_k\right)C\ .$$
\end{lemma}

\begin{proof}
	We know that for any $N\in\N$ it is true
	$$\sum^N_{k=0}BA_kC=B\left(\sum^N_{k=0}A_k\right)C\ .$$
	We want to now show that the left hand side converges to $B\left(\sum^\infty_{k=0}A_k\right)C$ for $N\rightarrow\infty$. Let $\varepsilon_1\in\R^+$ be fixed. Since the series $\sum^\infty_{k=0}A^k$ converges, we can find $N_0$ such that for every $N\in\N,N\geq N_0$ it holds 
	$$\norm{\sum^\infty_{k=0}A_k-\sum^N_{l=0}A_l}<\varepsilon_1\ .$$
	Then 
	\begin{align*}
		\norm{B\left(\sum^\infty_{k=0}A_k\right)C-\sum^N_{l=0}BA_lC}_F
		&=\norm{B\left(\sum^\infty_{k=0}A_k\right)C-B\left(\sum^N_{l=0}A_l\right)C}_F=
		\\
		=\norm{B\left(\sum^\infty_{k=0}A_k-\sum^N_{l=0}A_l\right)C}_F
		&\leq\norm{B}_F\norm{\sum^\infty_{k=0}A_k-\sum^N_{l=0}A_l}_F\norm{C}_F
		<\norm{B}_F\norm{C}_F\varepsilon_1\ .
	\end{align*}
	This concludes the proof that the series $\sum^\infty_{k=0}BA_kC$ converges to $B\left(\sum^\infty_{k=0}A_k\right)C$.
\end{proof}

\begin{definition}
	Let us have a matrix function $X(t)\colon\R\rightarrow\R^{n\times m}$. Then the derivative of the function is $$\frac{d}{dt}X(t)=\left(\frac{d}{dt}x_{i,j}(t)\right)_{n\times m}=\Big(\dot{x}_{i,j}(t)\Big)_{n\times m}\ .$$
\end{definition}

\begin{lemma}
\label{lem:matrixTimesVectorDerivative}
	For a matrix function $A(t)\colon\R\to\R^{n\times m}$ and a vector function \linebreak $v(t)\colon\R\to\R^m$ it holds 
	$$\frac{d}{dt}\left(A(t)v(t)\right)=\left(\frac{d}{dt}A(t)\right)v(t)+A(t)\frac{d}{dt}v(t)$$
\end{lemma}
	
\begin{proof}
	Can be simply shown by rewriting the vector $A(t)v(t)$ elementwise.
\end{proof}

\begin{lemma}
\label{lem:expprop}
	Let $A$, $B$ and $X$ be real $n\times n$ matrices. Then 
	\begin{enumerate}
		\item if $AB = BA$, then $e^{A}B = Be^{A}$,
		\item if $R$ is an invertible $n\times n$ matrix, then $e^{R^{-1}XR}=R^{-1}e^XR$,
		\item $\frac{d}{dt}e^{tX}=Xe^{tX}$, for $t \in \R$,
		\item if $AB = BA$, then $e^{A+B} = e^{A}e^B$.
	\end{enumerate}
\end{lemma}

\begin{proof}
	\begin{enumerate}
		\item
		Because of the convergence of the matrix exponential, we can use Lemma \ref{lem:matrixSeriesFactoring} and get
		$$e^{A}B=\sum^\infty_{k=0}\frac{1}{k!}A^{k}B\stackrel{AB=BA}{=\joinrel=\joinrel=}\sum^\infty_{k=0}\frac{1}{k!}BA^{k}=B\sum^\infty_{k=0}\frac{1}{k!}A^{k}=Be^{A}\ .$$
		
		\item Following from Lemma \ref{lem:matrixSeriesFactoring}, we have 
		\begin{longeq}
			e^{R^{-1}XR}=\sum^\infty_{k=0}\frac{1}{k!}(R^{-1}XR)^{k}=\sum^\infty_{k=0}\frac{1}{k!}R^{-1}X^{k}R=R^{-1}\left(\sum^\infty_{k=0}\frac{1}{k!}X^{k}\right)R=R^{-1}e^{X}R\ . 
		\end{longeq}

		\item The elements of the matrix $e^{tX}=\sum^\infty_{k=0}\frac{t^k}{k!}X^{k}=(e_{i,j}(t))_{n\times n}$ are equal to
		$$e_{i,j}(t)=\sum^\infty_{k=0}\frac{t^k}{k!}a^{(k)}_{i,j}\ ,$$
		where $X^k=(a^{(k)}_{i,j})_{n\times n}$. By Corollary \ref{cor:elementConvergence} the series $\sum^\infty_{k=0}\frac{t^k}{k!}a^{(k)}_{i,j}$ is absolutely convergent for every $t\in\R$. We can now differentiate the individual elements \citep[see][Věta 8.2.2]{Pick}.
		$$\frac{d}{dt}e_{i,j}(t)=\frac{d}{dt}\sum^\infty_{k=0}\frac{t^k}{k!}a^{(k)}_{i,j}=\sum^\infty_{k=1}\frac{t^{k-1}}{(k-1)!}a^{(k)}_{i,j}=\sum^\infty_{k=0}\frac{t^{k}}{k!}a^{(k+1)}_{i,j}\ .$$ 
		Using Lemma \ref{lem:matrixSeriesFactoring} we get the desired result
		\begin{longeq}
			\frac{d}{dt}e^{tX}=\left(\frac{d}{dt}e_{i,j}(t)\right)_{n\times n}=\left(\sum^\infty_{k=0}\frac{t^{k}}{k!}a^{(k+1)}_{i,j}\right)_{n\times n}=\sum^\infty_{k=0}\frac{t^k}{k!}X^{k+1}=X\sum^\infty_{k=0}\frac{t^k}{k!}X^{k}=Xe^{tX}\ .
		\end{longeq}

		\item For the following proof we use \citet[Theorem 5]{Klain}.
		
		Consider the function $g(t)=e^{t(A+B)}e^{-tB}e^{-tA}$. By the first and third points and by Lemma \ref{lem:matrixTimesVectorDerivative}, we have that for any $t\in\R$ 
		\begin{align*}
			g'(t)
			=&(A+B)e^{t(A+B)}e^{-tB}e^{-tA}+e^{t(A+B)}(-B)e^{-tB}e^{-tA}
			\\
			&\qquad\qquad\qquad\qquad\quad\quad +e^{t(A+B)}e^{-tB}(-A)e^{-tA}
			\\
			=&(A+B)g(t)-Bg(t)-Ag(t)
			\\
			=&O_{n\times n}\ .
		\end{align*}
		This implies, that the matrix $g(t)$ is a constant matrix. For any $t\in\R$, it therefore holds
		$$g(t)=g(0)=e^{0(A+B)}e^{-0A}e^{-0B}=e^Oe^Oe^O=I_n\ ,$$
		and hence
		$$I=g(t)=e^{t(A+B)}e^{-tB}e^{-tA}\ .$$
		Finally, after right multiplying both sides by $e^{tA}e^{tB}$, we obtain
		$$e^{tA}e^{tB}=e^{t(A+B)}\ .$$
	\end{enumerate}
\end{proof}

\begin{lemma}
	\label{lem:matrixExpIdentity}
	For any $a\in\C$ we have $e^{a I}=e^{a}I$.
\end{lemma}

\begin{proof}
	Follows straight from the definition of the matrix exponential.
	$$e^{a I}=\sum^\infty_{k=0}\frac{a^k}{k!}I^k=\left(\delta_{i,j}\sum^\infty_{k=0}\frac{a^k}{k!}\right)_{n\times n}=\left(\delta_{i,j}e^a\right)_{n\times n}=e^aI$$
\end{proof}

Now, using the properties in Lemma \ref{lem:expprop}, we can see that $\dot{x}(t)=Ax(t)$ is solved by $x(t)=e^{tA}x(0)$. The solution is unique which follows from the general theory of linear differential equations \cite[see][Věta 13.5.1]{Pick}.

\begin{claim}
\label{claim:uniqueness}
	The autonomous linear system $\dot{x}(t)=Ax(t)$ with an initial condition $x(0)$ is uniquely solved by $x(t)=e^{tA}x(0)$.
\end{claim}

\subsection{Stability of Linear Autonomous Systems}

Typically, we require the autonomous system to stabilize itself back into its stable state after some disturbances.

\begin{definition}
	The linear autonomous system $\dot{x}(t)=Ax(t)$ is \termdef{stable}, if for any initial state $x(0)\in\R^n$ the state vector $x(t)$ converges to $\nullvector$ for $t\to\infty$.
\end{definition}

Let $A$ be a real square matrix. Then there is a regular matrix $R\in \R^{n\times n}$ such that the matrix
$$J=R^{-1}AR$$
is in a Jordan normal form. By substituting $x(t)=Ry(t)$, which is equivalent to changing the basis of the system, we get 
\begin{align*}
	R\dot{y}(t)&=ARy(t) \\
	\dot{y}(t)&=R^{-1}ARy(t) \\
	\dot{y}(t)&=Jy(t)\ .
\end{align*}
Therefore, by Claim \ref{claim:uniqueness}, the unique solution is
$$y(t)=e^{tJ}y(0)\ .$$
It is sufficient to determine when $y(t)$ converges to \nullvector, because since $R$ is an invertible matrix, $x(t)$ converges to $\nullvector$ if and only if $y(t)$ converges to $\nullvector$.

We know that every Jordan block $J_{\lambda,n}$ in the matrix $J$ is of the form \linebreak $J_{\lambda,n}=\lambda I_n+N_n$, $n \in\N$, where $N_n=\left(n_{i,j}\right)_{n\times n}$ is the nilpotent matrix satisfying $n_{i,j}=\delta_{i,j-1}$. 
It is also true that $(N_n)^k_{i,j}=\delta_{i,j-k}$ and $(N_n)^n=O_{n \times n}$, since every right multiplication by the matrix $N$ shifts the multiplied matrix's columns to the right by one column, that is, it maps matrix $(v_1,\ldots,v_n)$ onto $(\nullvector,v_1,\ldots,v_{n-1})$. For example, in case of $n=4$ we have
\begin{equation*}
	N_4=
	\begin{pmatrix}
		0 & 1 & 0 & 0 \\
		0 & 0 & 1 & 0 \\
		0 & 0 & 0 & 1 \\
		0 & 0 & 0 & 0 
	\end{pmatrix},\ 
	(N_4)^2=
	\begin{pmatrix}
		0 & 0 & 1 & 0 \\
		0 & 0 & 0 & 1 \\
		0 & 0 & 0 & 0 \\
		0 & 0 & 0 & 0 
	\end{pmatrix},\ 
	(N_4)^3=
	\begin{pmatrix}
		0 & 0 & 0 & 1 \\
		0 & 0 & 0 & 0 \\
		0 & 0 & 0 & 0 \\
		0 & 0 & 0 & 0 
	\end{pmatrix}
	.
\end{equation*}

By Lemma \ref{lem:expprop}, for each Jordan block $J_{\lambda,n}$, we have
$$e^{tJ_{\lambda,n}}=e^{t(\lambda I_n + N_n)}=e^{t\lambda I_n}e^{tN_n}=e^{\lambda t}e^{tN_n}\ .$$
Let $\lambda = a+ib$ where $a$,$b \in \R$, then
$$e^{tJ_{\lambda,n}}=e^{at}e^{ibt}e^{tN}\ .$$
We know that $|e^{ibt}|=1$ and that
$$e^{tN}=\sum^\infty_{k=0}\frac{t^k}{k!}N^k=\sum^{n-1}_{k=0}\frac{t^k}{k!}N^k\ ,$$
since $(N_n)^n=O_{n \times n}$. Therefore, we can see that every element of the matrix $e^{tN}$ is a polynomial in $t$ of degree less than $n$. It follows that $e^{tJ_{\lambda,n}}$ approaches $O_{n \times n}$ for $t\rightarrow\infty$ if and only if
$$\lim_{t\to\infty}e^{at}t^{n-1}=0\ .$$
This holds for any $n\in\N$ if and only if $a<0$. 

Since any block diagonal matrix to the power of any natural number preserves its block form, we can write
\begin{equation*}
	J=
	\begin{pmatrix}
		J_{\lambda_1,n_1} & 0 & \cdots & 0 \\
		0 & J_{\lambda_2,n_2} & \cdots & 0 \\
		\vdots & \vdots & \ddots & \vdots \\
		0 & 0 & \cdots & J_{\lambda_r,n_r}
	\end{pmatrix},
	\quad 
	e^J=
	\begin{pmatrix}
		e^{J_{\lambda_1,n_1}} & 0 & \cdots & 0 \\
		0 & e^{J_{\lambda_2,n_2}} & \cdots & 0 \\
		\vdots & \vdots & \ddots & \vdots \\
		0 & 0 & \cdots & e^{J_{\lambda_r,n_r}}
	\end{pmatrix}
	,
\end{equation*}
where the zeroes in the matrices represent zero matrices of appropriate sizes. Therefore, since $y(0)$ is a constant vector, we see that $y(t)=e^{tJ}y(0)$ converges to $\nullvector$ if (and only if, because of the uniqueness of the solution) all the eigenvalues $\lambda_i$ of the matrix $A$ have negative real parts. As the last step, we calculate $x(t)=Ry(t)$ and $x(0)=Ry(0)$. Let us formulate this result into a theorem.

\begin{theorem}
\label{theorem:stability}
	The system $\dot{x}=Ax(t)$ is stable if and only if all eigenvalues of the matrix $A$ have negative real parts.
\end{theorem}

\section{Linear System With Control}

\begin{definition}
	A \termdef{continuous dynamical linear system with control u} is a system of linear differential equations of first order with constant coefficients in the form $$\dot{x}(t)=Ax(t)+Bu(t)\ ,$$ where the function $x(t)\colon\R^+\to\R^n$ is a \termdef{state vector} (\termdef{state} for short) of the system, $A\in\R^{n\times n}$ is a \termdef{matrix of coefficients} of the system, $B\in\R^{n\times m}$ is a \termdef{control matrix} of the system and the continuous function $u(t)\colon\R^+\to\R^m$ is a \termdef{control vector} of the system. The \termdef{initial condition} of the system is the state $x(0)$.

	We call this system the $(A,B)$ system for short.
\end{definition}

In a general case, this is called an \termdef{open-loop control} system because the control is not dependent on the previous state of the system.

We can imagine such a system as follows. The first summand of the right-hand side, $Ax(t)$, of the equation $\dot{x}(t)=Ax(t)+Bu(t)$ can be thought of as the model of the machine or the event that we want to control and the second summand, $Bu(t)$, as our control mechanism. The matrix $B$ fulfils the role of a ``control board'' and the control vector $u(t)$ is us deciding, which ``levers'' and ``buttons'' we want to push. 

Of course, if we want this system to be self-regulating, we cannot input our own values into $u(t)$, and therefore $u(t)$ has to be calculated from the state of our system.

\begin{definition}
	Let us have a linear differential system with the control $u(t)$ defined as
	$$u(t)=Fx(t)\ ,$$
	where $F\in\R^{m\times n}$ is a \termdef{feedback matrix}. This system is then called a \termdef{closed-loop control} system or a \termdef{linear feedback control} system.

	For short, we call this system the $(A,B,F)$ system.
\end{definition}

Usually, we are given an autonomous system and we need to find a feedback matrix $F$ such that the resulting system has some desired behavior. The feedback control system can be expressed as the linear autonomous system
$$\dot{x}(t)=Ax(t)+BFx(t)=(A+BF)x(t)\ .$$

\begin{definition}
	The linear feedback system $(A,B,F)$ is \termdef{stable}, if the linear autonomous system $\dot{x}(t)=(A+BF)x(t)$ is stable.
\end{definition}

By Theorem \ref{theorem:stability}, we now know that an $(A,B,F)$ system is stable if all eigenvalues of the matrix $A+BF$ have negative real parts. Therefore, we are left to provide a suitable feedback matrix $F \in \R^{n \times n}$. This requirement can also be expressed through the characteristic polynomial of the matrix $A~+~BF$, since the roots of the characteristic polynomial of a matrix are precisely eigenvalues of the matrix.

\begin{definition}
	Let $A$ be a $n\times n$ matrix. Then the \termdef{characteristic polynomial}~of~$A$, denoted by $\chi_A$, is defined as $$\chi_A(s)=\textnormal{det}(sI_n-A)\ .$$
\end{definition}

Through these observations we got to a conclusion, that we need to find a feedback matrix $F$ such that the characteristic polynomial of the matrix $A+BF$ is $$\chi_{A+BF}=(x-\lambda_1)(x-\lambda_2)\cdots(x-\lambda_n)\ ,$$ where all its roots $\lambda_1,\lambda_2,\ldots,\lambda_n \in \C$ have negative real parts. This leads to an important definition.

\begin{definition}
    Let $\K$ be a field and let $A \in \K^{n \times n}$, $B \in \K^{n \times m}$, $n,m \in \N$. We say that a polynomial $\chi$ is \termdef{assignable for the pair} $(A,B)$ if there exists such a matrix $F\in\K^{m \times n}$ that $$\chi_{A+BF}=\chi\ .$$
\end{definition}

The pole shifting theorem states, that if $A$ and $B$ are ``sensible'' in a sense that we discuss in the next section, then an arbitrary monic polynomial $\chi$ of degree $n$ can be assigned to the pair $(A,B)$. It also claims that it is immaterial over what field $A$ and $B$ are.

\section{Discrete-time systems}

Let us have a continuous dynamical system $\dot{x}(t)=A_1x(t)$, where $A_1$ is a real square matrix. We \textit{discretize} the time, that is, instead of using continuous real-time values of $x(t)$ and $\dot{x}(t)$, we are interested in these values only at discrete \textit{sampling times} $0,\delta,2\delta,\ldots,k\delta,\ldots$ where $\delta\in\R^+$. We denote the states at each sampling time as
$$x_k=x(k\delta)\ ,k\in\N_0\ .$$
The solution of this system is by Theorem \ref{claim:uniqueness} precisely $x(t)=e^{tA_1}x(0)$. For some fixed $k\in\N$ we get $x_k=x(k\delta)=e^{k\delta A_1}x(0)$. Using the fourth point of Lemma \ref{lem:expprop} we obtain 
\begin{align*}
	x_{k+1}
	&=e^{(k+1)\delta A_1}x(0) \\
	&=e^{\delta A_1 +k\delta A_1}x(0) \\
	&=e^{\delta A_1}e^{k\delta A_1}x(0) \\
	&=e^{\delta A_1}x_k \\
	&=Ax_k
\end{align*}
by choosing $A=e^{\delta A_1}$. We see that the value of $x$ at the sample time $k$ can be calculated from its previous value. We now define such a system. The definition holds for any field $\K$.

\begin{definition}
	Let $\K$ be a field. A \termdef{discrete dynamical linear system} is a system of equations
	$$x_{k+1}=Ax_k,\ k\in\N_0\ ,$$
	where $x_k\in \K^n$ is a \termdef{state vector} (\termdef{state} for short) of the system and the matrix $A\in \K^{n\times n}$ is a \termdef{matrix of coefficients} of the system. The \termdef{initial condition} of the system is the state $x(0)$.
\end{definition}

Similarly, we can define a discrete dynamical linear system with control.

\begin{definition}
	Let $\K$ be a field. A \termdef{discrete dynamical linear system with control u} is a system of equations
	$$x_{k+1}=Ax_k+Bu_k,\ k\in\N_0\ ,$$
	where $x_k\in\K^n$ is a \termdef{state vector} (\termdef{state} for short) of the system, $A\in\K^{n\times n}$ is a matrix of coefficients, $B\in\K^{n\times m}$ is a control matrix and $u_k\in\K^m$ is a control vector. The \termdef{initial condition} of the system is the state $x_0$.

	We call this system the \termdef{discrete $(A,B)$} system.
\end{definition}